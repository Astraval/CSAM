{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T17:48:40.949614Z",
     "start_time": "2025-06-05T17:48:40.871731Z"
    }
   },
   "source": [
    "import copy\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from src.optimizers.LagrangianTrainer import LagrangianTrainer\n",
    "from src.optimizers.SimpleTrainer import SimpleTrainer\n",
    "from src.utils import dataset\n",
    "from src.utils.evaluation import evaluate_fgsm_accuracy\n",
    "from src.optimizers.HypercubeTrainer import HypercubeTrainer\n",
    "from src.utils.evaluation import evaluate_accuracy\n",
    "from src.cert import Safebox"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T17:48:49.845602Z",
     "start_time": "2025-06-05T17:48:41.900898Z"
    }
   },
   "id": "c675c831c2e4942d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T17:48:50.095996Z",
     "start_time": "2025-06-05T17:48:49.848126Z"
    }
   },
   "id": "1a0613def2799a06",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "def get_model(output_dim=10):\n",
    "    \"\"\"Returns a simple CNN model.\"\"\"\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 8, kernel_size=5, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(8, 1, kernel_size=5, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(576, output_dim),\n",
    "    ).to(DEVICE)\n",
    "    return model\n",
    "def get_model_cifar10(seed=0, output_dim=10):\n",
    "    \"\"\"Returns a simple CNN model.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(3, 8, kernel_size=5, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(8, 3, kernel_size=5, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(2352, output_dim),\n",
    "    ).to(DEVICE)\n",
    "    return model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T17:48:50.312627Z",
     "start_time": "2025-06-05T17:48:50.098114Z"
    }
   },
   "id": "4e0a95cef96b5757",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "from src.utils.dataset import reduce_dataset\n",
    "\n",
    "train_dataset, val_dataset = dataset.get_fashion_mnist_dataset()\n",
    "#train_dataset = reduce_dataset(train_dataset, num_samples=300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T17:48:50.668451Z",
     "start_time": "2025-06-05T17:48:50.314632Z"
    }
   },
   "id": "9046dfd0a62bb615",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "simple_model = get_model()\n",
    "trainer = SimpleTrainer(simple_model, device=DEVICE)\n",
    "simple_model = trainer.train(train_dataset, val_dataset, loss_obj=0.000000000000001, max_iters=3000, batch_size=64, lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73033846897c5935",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coucou\n",
      "FGSM Accuracy Simple Training 0.03189999982714653\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#print(\"Accuracy Simple Training\", evaluate_accuracy(val_dataset, simple_model, num_samples=len(val_dataset), device=DEVICE))\n",
    "print(\"FGSM Accuracy Simple Training\", evaluate_fgsm_accuracy(val_dataset, simple_model, num_samples=len(val_dataset), device=DEVICE, epsilon=0.2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T12:28:53.160036Z",
     "start_time": "2025-06-05T12:28:51.173807Z"
    }
   },
   "id": "511d020827ebfaec",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05549999698996544\n"
     ]
    }
   ],
   "source": [
    "bmodel_test = Safebox.modelToBModel(simple_model)\n",
    "Safebox.assign_epsilon(bmodel_test, 1e-4*4.0)\n",
    "trainer = HypercubeTrainer(simple_model, \"cuda\", False)\n",
    "trainer._interval_model = bmodel_test\n",
    "print(trainer._evaluate_min_val_acc(val_dataset, len(val_dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T09:37:31.471011Z",
     "start_time": "2025-06-05T09:37:29.393199Z"
    }
   },
   "id": "1952922071d9533c",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Started Multiphase Trainer for 1 phases ==========\n",
      "First time train is called. Initial training phase started with volume 0.0001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:48<00:00, 20.62it/s, loss=0.375, min_val_acc=0.821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Training completed with loss  0 ----------\n",
      "=> Initial center accuracy is 0.8338000178337097\n"
     ]
    }
   ],
   "source": [
    "from src.optimizers import interval_narrowers\n",
    "from src.optimizers.ConstrainedVolumeMultiphaseTrainer import ConstrainedVolumeMultiphaseTrainer\n",
    "\n",
    "model = get_model(output_dim=10)\n",
    "optimizer = HypercubeTrainer(model, device=DEVICE)\n",
    "multiphase_trainer = ConstrainedVolumeMultiphaseTrainer(\n",
    "    optimizer, \n",
    "    inflate_function=interval_narrowers.inflate_multiplier(2.0),\n",
    "    narrow_function=interval_narrowers.narrower_halver(0.5),\n",
    "    starting_value=1e-4, \n",
    "    quiet=False\n",
    ")\n",
    "multiphase_trainer.train(\n",
    "    1, val_dataset,\n",
    "    train_dataset, val_dataset, loss_obj=0.000000000000001, max_iters=1000, batch_size=64, lr=1e-3\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T17:49:42.473904Z",
     "start_time": "2025-06-05T17:48:50.673973Z"
    }
   },
   "id": "3eb30db4134b45e0",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coucou\n",
      "FGSM Accuracy  0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "model = Safebox.bmodelToModel(multiphase_trainer.result())\n",
    "print(\"FGSM Accuracy \", evaluate_fgsm_accuracy(val_dataset, model, num_samples=len(val_dataset), epsilon=0.1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T17:36:11.339747Z",
     "start_time": "2025-06-05T17:36:06.594250Z"
    }
   },
   "id": "9ca73a3106cbfd07",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0032, device='cuda:0')\n",
      "tensor(0.0032, device='cuda:0')\n",
      "tensor(0.0032, device='cuda:0')\n",
      "tensor(0.0032, device='cuda:0')\n",
      "tensor(0.0032, device='cuda:0')\n",
      "tensor(0.0032, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "modelU, modelL = copy.deepcopy(model), copy.deepcopy(model)\n",
    "for layerU, layerL, layerB in zip(modelU, modelL, optimizer._interval_model): \n",
    "    if isinstance(layerB, Safebox.BDense) or isinstance(layerB, Safebox.BConv2d): \n",
    "        layerU.weight.data.copy_(layerB.W_c+5*layerB.W_u)\n",
    "        layerL.weight.data.copy_(layerB.W_c-10*layerB.W_l)\n",
    "        layerU.bias.data.copy_(layerB.b_c+5*layerB.b_u)\n",
    "        layerL.bias.data.copy_(layerB.b_c-10*layerB.b_l)\n",
    "        print(layerB.W_u.mean())\n",
    "        print(layerB.b_l.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T11:27:38.871149Z",
     "start_time": "2025-06-05T11:27:38.618600Z"
    }
   },
   "id": "bd751960f9d4611f",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model U Accuracy  0.8026000261306763\n",
      "model L Accuracy  0.7675999999046326\n",
      "model Accuracy  0.8087999820709229\n"
     ]
    }
   ],
   "source": [
    "print(\"model U Accuracy \", evaluate_accuracy(val_dataset, modelU, num_samples=len(val_dataset), ))\n",
    "print(\"model L Accuracy \", evaluate_accuracy(val_dataset, modelL, num_samples=len(val_dataset), ))\n",
    "print(\"model Accuracy \", evaluate_accuracy(val_dataset, model, num_samples=len(val_dataset), ))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T11:27:45.569145Z",
     "start_time": "2025-06-05T11:27:39.593052Z"
    }
   },
   "id": "bc488f84e1bf889d",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-1.)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=True)))\n",
    "X.min()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T11:29:40.845937Z",
     "start_time": "2025-06-05T11:29:40.467442Z"
    }
   },
   "id": "e5ac6934017fd877",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New Layer ---\n",
      "Simple weight :  -0.02653699927031994  std  0.13423000276088715\n",
      "Flat weight :  0.018327999860048294  std  0.14879299700260162\n",
      "Simple bias :  0.05447600036859512  std  0.1779630035161972\n",
      "Flat bias :  -0.046386998146772385  std  0.13203200697898865\n",
      "--- New Layer ---\n",
      "Simple weight :  0.024111000820994377  std  0.06942799687385559\n",
      "Flat weight :  0.007294999901205301  std  0.07857400178909302\n",
      "Simple bias :  0.11389800161123276  std  nan\n",
      "Flat bias :  -0.05412000045180321  std  nan\n",
      "--- New Layer ---\n",
      "Simple weight :  -0.006694999989122152  std  0.03820300102233887\n",
      "Flat weight :  -0.005133999977260828  std  0.0362280011177063\n",
      "Simple bias :  -0.0016080000204965472  std  0.029248999431729317\n",
      "Flat bias :  -0.014062999747693539  std  0.04829400032758713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fasterling Pierre\\AppData\\Local\\Temp\\ipykernel_24724\\1052549600.py:6: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  print(\"Simple bias : \", layerSimple.bias.mean().round(decimals=6).item(), \" std \", layerSimple.bias.std().round(decimals=6).item())\n",
      "C:\\Users\\Fasterling Pierre\\AppData\\Local\\Temp\\ipykernel_24724\\1052549600.py:7: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  print(\"Flat bias : \", layerFlat.b_c.mean().round(decimals=6).item(), \" std \", layerFlat.b_c.std().round(decimals=6).item())\n"
     ]
    }
   ],
   "source": [
    "for layerSimple, layerFlat in zip(simple_model, optimizer.result()):\n",
    "    if isinstance(layerSimple, torch.nn.Linear) or isinstance(layerSimple, torch.nn.Conv2d): \n",
    "        print(\"--- New Layer ---\")\n",
    "        print(\"Simple weight : \", layerSimple.weight.mean().round(decimals=6).item(), \" std \", layerSimple.weight.std().round(decimals=6).item())\n",
    "        print(\"Flat weight : \", layerFlat.W_c.mean().round(decimals=6).item(), \" std \", layerFlat.W_c.std().round(decimals=6).item())\n",
    "        print(\"Simple bias : \", layerSimple.bias.mean().round(decimals=6).item(), \" std \", layerSimple.bias.std().round(decimals=6).item())\n",
    "        print(\"Flat bias : \", layerFlat.b_c.mean().round(decimals=6).item(), \" std \", layerFlat.b_c.std().round(decimals=6).item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-04T08:05:19.813266Z",
     "start_time": "2025-06-04T08:05:19.551830Z"
    }
   },
   "id": "ff31a1343e8c5550",
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Lagrangian experiments"
   ],
   "id": "2a9f8a6e5c2d2bab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T22:35:18.225425Z",
     "start_time": "2025-06-01T22:31:33.386557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.optimizers.volumes import LogVolume\n",
    "\n",
    "model = get_model(output_dim=10)\n",
    "optimizer = LagrangianTrainer(model,LogVolume(epsilon=1e-8), device=DEVICE)\n",
    "optimizer.set_volume_constrain(1e-4) # start with a small volume at first\n",
    "print(optimizer._volume_function(optimizer._interval_model))\n",
    "optimizer.train(\n",
    "    train_dataset, val_dataset, loss_obj=-0.000000000000001, max_iters=3000, batch_size=64, lr=1e-4\n",
    ")"
   ],
   "id": "b80923e351a1571",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-8.5171, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [03:44<00:00, 13.37it/s, loss=0.405, min_val_acc=0.531, current_volume=-8.53] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Training completed with loss  0 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.7109000086784363\n",
      "Mean layer intervals W_u tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(0.0002, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals W_l tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(0.0002, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals b_u tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(0.0002, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals b_l tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(0.0002, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals W_u tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(0.0003, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals W_l tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(0.0003, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals b_u tensor(6.2757e-05, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(nan, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals b_l tensor(6.2233e-05, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(nan, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals W_u tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(0.0006, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals W_l tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(0.0006, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals b_u tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(0.0005, device='cuda:0', grad_fn=<StdBackward0>)\n",
      "Mean layer intervals b_l tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>)  std  tensor(0.0005, device='cuda:0', grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fasterling Pierre\\AppData\\Local\\Temp\\ipykernel_4020\\4181305677.py:7: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  print(\"Mean layer intervals b_u\", layer.b_u.mean(), \" std \", layer.b_u.std())\n",
      "C:\\Users\\Fasterling Pierre\\AppData\\Local\\Temp\\ipykernel_4020\\4181305677.py:8: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  print(\"Mean layer intervals b_l\", layer.b_l.mean(), \" std \", layer.b_l.std())\n"
     ]
    }
   ],
   "source": [
    "interval_model = optimizer.result()\n",
    "print(\"Accuracy \", evaluate_accuracy(val_dataset, Safebox.bmodelToModel(interval_model), num_samples=len(val_dataset)))\n",
    "for layer in interval_model:\n",
    "    if isinstance(layer, Safebox.BDense) or isinstance(layer, Safebox.BConv2d):\n",
    "        print(\"Mean layer intervals W_u\", layer.W_u.mean(), \" std \", layer.W_u.std())\n",
    "        print(\"Mean layer intervals W_l\", layer.W_l.mean(), \" std \", layer.W_l.std())\n",
    "        print(\"Mean layer intervals b_u\", layer.b_u.mean(), \" std \", layer.b_u.std())\n",
    "        print(\"Mean layer intervals b_l\", layer.b_l.mean(), \" std \", layer.b_l.std())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-01T22:38:07.559575Z",
     "start_time": "2025-06-01T22:38:04.948291Z"
    }
   },
   "id": "1b50227a26282546",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "model = Safebox.bmodelToModel(optimizer.result())\n",
    "print(\"Accuracy \", evaluate_accuracy(val_dataset, model, num_samples=10000))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-01T11:19:20.252182Z",
     "start_time": "2025-06-01T11:19:18.788649Z"
    }
   },
   "id": "b9d6317752bffce3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.12359999865293503\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "60ed13093b04b25a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
