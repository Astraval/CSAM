{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-06T23:32:22.917008Z",
     "start_time": "2025-06-06T23:32:14.024341Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.bayes.BayesianModel import BayesianModel\n",
    "from src.optimizers.SAMTrainer import SAMTrainer\n",
    "from src.optimizers.SimpleTrainer import SimpleTrainer\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.optimizers.SimpleTrainer import SimpleTrainer\n",
    "from src.utils.evaluation import evaluate_run\n",
    "from src.utils import dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from src.optimizers import interval_narrowers\n",
    "from src.optimizers.ConstrainedVolumeMultiphaseTrainer import ConstrainedVolumeMultiphaseTrainer\n",
    "from src.optimizers.PGDTrainer import PGDTrainer\n",
    "from src.optimizers.HypercubeTrainer import HypercubeTrainer, ConstrainedVolumeTrainer\n",
    "from src.utils.evaluation import evaluate_accuracy, evaluate_fgsm_accuracy, evaluate_certified_adv_accuracy\n",
    "from src.cert import Safebox\n",
    "from src.bayes.DiagonalGaussianBayesianModel import DiagonalGaussianBayesianModel\n",
    "from src.bayes.UniformBayesianModel import UniformBayesianModel\n",
    "from src.bayes.BayesianModel import BayesianModel\n",
    "import math\n",
    "from src.optimizers.SAMTrainer import SAMTrainer\n",
    "from torch.utils.data import DataLoader, Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T23:32:28.619686Z",
     "start_time": "2025-06-06T23:32:22.920018Z"
    }
   },
   "id": "5b2867ee52190887",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T23:32:29.009414Z",
     "start_time": "2025-06-06T23:32:28.621843Z"
    }
   },
   "id": "6ef52ac6b4db9728",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size:  48000\n",
      "Test Dataset Size:  12000\n",
      "Validation Dataset Size:  10000\n"
     ]
    }
   ],
   "source": [
    "mnist_train_test, mnist_val = dataset.get_mnist_dataset(root=\"./data\")\n",
    "mnist_train, mnist_test = dataset.split_dataset(mnist_train_test, split_proportion=0.8)\n",
    "print(\"Train Dataset Size: \", len(mnist_train))\n",
    "print(\"Test Dataset Size: \", len(mnist_test))\n",
    "print(\"Validation Dataset Size: \", len(mnist_val))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T23:32:29.554420Z",
     "start_time": "2025-06-06T23:32:29.012415Z"
    }
   },
   "id": "f5d0ef0945b55e2f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size:  48000\n",
      "Test Dataset Size:  12000\n",
      "Validation Dataset Size:  10000\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_train_test, fashion_mnist_val = dataset.get_fashion_mnist_dataset(root=\"./data\")\n",
    "fashion_mnist_train, fashion_mnist_test = dataset.split_dataset(fashion_mnist_train_test, split_proportion=0.8)\n",
    "print(\"Train Dataset Size: \", len(fashion_mnist_train))\n",
    "print(\"Test Dataset Size: \", len(fashion_mnist_test))\n",
    "print(\"Validation Dataset Size: \", len(fashion_mnist_val))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T00:06:05.658429Z",
     "start_time": "2025-06-07T00:06:05.313576Z"
    }
   },
   "id": "4b44e76e8b260b8d",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_model(output_dim=10):\n",
    "    \"\"\"Returns a simple CNN model.\"\"\"\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 8, kernel_size=5, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(8, 1, kernel_size=5, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(576, output_dim),\n",
    "    ).to(DEVICE)\n",
    "    return model\n",
    "\n",
    "def make_bayesian_gaussian(interval_model: torch.nn.Sequential, bound_mul: float=70) -> BayesianModel:\n",
    "    \"\"\"\n",
    "    This function assumes bound model to be already centered so it will only use W_u.\n",
    "    \"\"\"\n",
    "    center_model = Safebox.bmodelToModel(interval_model)\n",
    "    std_params = []\n",
    "    for layerInterval in interval_model:\n",
    "        if isinstance(layerInterval, Safebox.BDense) or isinstance(layerInterval, Safebox.BConv2d):\n",
    "            std_params.append((layerInterval.W_u*bound_mul).clone().detach())\n",
    "            std_params.append((layerInterval.b_u*bound_mul).clone().detach())\n",
    "    return DiagonalGaussianBayesianModel(\n",
    "        center_model, std_params\n",
    "    )\n",
    "def make_bayesian_uniform(interval_model: torch.nn.Sequential, bound_mul: float=70) -> BayesianModel:\n",
    "    bound_params = []\n",
    "    center_model = Safebox.bmodelToModel(interval_model)\n",
    "    for layerInterval in interval_model:\n",
    "        if isinstance(layerInterval, Safebox.BDense) or isinstance(layerInterval, Safebox.BConv2d):\n",
    "            bound_params.append((layerInterval.W_u*100).clone().detach())\n",
    "            bound_params.append((layerInterval.b_u*100).clone().detach())\n",
    "        \n",
    "\n",
    "    return UniformBayesianModel(\n",
    "        center_model, bound_params\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T23:32:29.944528Z",
     "start_time": "2025-06-06T23:32:29.559418Z"
    }
   },
   "id": "9ea4138fa6212ac3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Started Multiphase Trainer for 7 phases ==========\n",
      "First time train is called. Initial training phase started with volume 5e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.81it/s, loss=0.666, min_val_acc=0.835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Initial center accuracy is 0.8593000173568726\n",
      "-> Starting phase 6\n",
      "-> Current Volume interval : [5e-05, INFINITY]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.87it/s, loss=0.446, min_val_acc=0.876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Phase done\n",
      "-> Center Accuracy is 0.8878999948501587.\n",
      "-> Generalization is above minimum accuracy by 0.10789999485015866.!\n",
      "-> Starting phase 6\n",
      "-> Current Volume interval : [0.0001, INFINITY]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 14.27it/s, loss=0.432, min_val_acc=0.874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Phase done\n",
      "-> Center Accuracy is 0.9025999903678894.\n",
      "-> Generalization is above minimum accuracy by 0.12259999036788938.!\n",
      "-> Starting phase 6\n",
      "-> Current Volume interval : [0.0002, INFINITY]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.55it/s, loss=0.419, min_val_acc=0.854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Phase done\n",
      "-> Center Accuracy is 0.9142000079154968.\n",
      "-> Generalization is above minimum accuracy by 0.1342000079154968.!\n",
      "-> Starting phase 6\n",
      "-> Current Volume interval : [0.0004, INFINITY]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 15.33it/s, loss=0.591, min_val_acc=0.815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Phase done\n",
      "-> Center Accuracy is 0.9143999814987183.\n",
      "-> Generalization is above minimum accuracy by 0.13439998149871824.!\n",
      "-> Starting phase 6\n",
      "-> Current Volume interval : [0.0008, INFINITY]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 14.00it/s, loss=0.461, min_val_acc=0.754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Phase done\n",
      "-> Center Accuracy is 0.9146000146865845.\n",
      "-> Generalization is above minimum accuracy by 0.13460001468658445.!\n",
      "-> Starting phase 6\n",
      "-> Current Volume interval : [0.0016, INFINITY]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 14.24it/s, loss=1.64, min_val_acc=0.572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Phase done\n",
      "-> Center Accuracy is 0.90420001745224.\n",
      "-> Generalization is above minimum accuracy by 0.12420001745223996.!\n",
      "Training succeeded !\n"
     ]
    }
   ],
   "source": [
    "# Setting random seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "h_model = get_model(output_dim=10)\n",
    "optimizer = HypercubeTrainer(h_model, device=DEVICE)\n",
    "multiphase_trainer = ConstrainedVolumeMultiphaseTrainer(\n",
    "    optimizer, \n",
    "    inflate_function=interval_narrowers.inflate_multiplier(2.0),\n",
    "    narrow_function=interval_narrowers.narrower_halver(0.5),\n",
    "    starting_value=1e-4*0.5, \n",
    "    min_acc_limit=0.78,\n",
    "    quiet=False\n",
    ")\n",
    "restart = not multiphase_trainer.train(\n",
    "    7, mnist_val,\n",
    "    mnist_train, mnist_val, loss_obj=0.0, max_iters=100, batch_size=64, lr=1e-3\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T23:33:47.923257Z",
     "start_time": "2025-06-06T23:32:29.947533Z"
    }
   },
   "id": "5884b06af801eb1",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X, y = next(iter(DataLoader(mnist_test, batch_size=200, shuffle=True)))\n",
    "X_noise, _ = next(iter(DataLoader(fashion_mnist_test, batch_size=200, shuffle=True)))\n",
    "X_noise_detection = torch.concat([X_noise, X], dim=0)\n",
    "y_noise_detection = torch.concat([torch.ones_like(y), torch.zeros_like(y)])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T00:12:51.087139Z",
     "start_time": "2025-06-07T00:12:50.549343Z"
    }
   },
   "id": "11bb91dd7dbfdde2",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Bayesian neural network  tensor(0.8700)\n",
      "Accuracy in noise detection  tensor(0.7075)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interval_model = multiphase_trainer.result()\n",
    "bayesian_model_gaussian = make_bayesian_gaussian(interval_model, bound_mul=0.0)\n",
    "mean, std, entropy = bayesian_model_gaussian.predict(X, n_samples=100, device=DEVICE)\n",
    "mean, std, entropy = mean.cpu(), std.cpu(), entropy.cpu()\n",
    "print(\"Accuracy Bayesian neural network \", (mean.argmax(dim=1)==y).sum()/200)\n",
    "mean, std, entropy = bayesian_model_gaussian.predict(X_noise_detection, n_samples=100, device=DEVICE)\n",
    "mean, std, entropy = mean.cpu(), std.cpu(), entropy.cpu()\n",
    "print(\"Accuracy in noise detection \", ((entropy>1.0) == y_noise_detection.cpu()).sum()/400)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T00:12:54.994490Z",
     "start_time": "2025-06-07T00:12:51.889957Z"
    }
   },
   "id": "38de1c460e9ae8d5",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:48<00:00, 14.50it/s, loss=0.178, val_acc=0.93]  \n"
     ]
    }
   ],
   "source": [
    "adam_model = get_model()        \n",
    "trainer = SimpleTrainer(adam_model, device=DEVICE, quiet=False, acc_evaluation_steps=70)\n",
    "trainer.train(mnist_train, mnist_val, loss_obj=0.0, max_iters=700, batch_size=64, lr=1e-3)\n",
    "adam_model = trainer.result()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T00:03:14.094973Z",
     "start_time": "2025-06-07T00:02:25.506281Z"
    }
   },
   "id": "540fc799415d828c",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Bayesian neural network  tensor(0.9200)\n",
      "Accuracy in noise detection  tensor(0.6775)\n"
     ]
    }
   ],
   "source": [
    "interval_model = Safebox.modelToBModel(adam_model)\n",
    "Safebox.assign_epsilon(interval_model, 3*1e-3)\n",
    "bayesian_model_gaussian = make_bayesian_gaussian(interval_model, bound_mul=0.0)\n",
    "mean, std, entropy = bayesian_model_gaussian.predict(X, n_samples=100, device=DEVICE)\n",
    "mean, std, entropy = mean.cpu(), std.cpu(), entropy.cpu()\n",
    "print(\"Accuracy Bayesian neural network \", (mean.argmax(dim=1)==y).sum()/200)\n",
    "mean, std, entropy = bayesian_model_gaussian.predict(X_noise_detection, n_samples=100, device=DEVICE)\n",
    "mean, std, entropy = mean.cpu(), std.cpu(), entropy.cpu()\n",
    "print(\"Accuracy in noise detection \", ((entropy>1.0) == y_noise_detection.cpu()).sum()/400)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T00:13:09.852756Z",
     "start_time": "2025-06-07T00:13:06.954483Z"
    }
   },
   "id": "52a32fdc795d6158",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f37fa80bfbb3e4cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
