{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-01T10:56:33.795110Z",
     "start_time": "2025-06-01T10:56:32.549036Z"
    }
   },
   "source": [
    "from cooper.formulations import Lagrangian\n",
    "\n",
    "from src.optimizers.LagrangianTrainer import LagrangianTrainer\n",
    "from src.optimizers.SimpleTrainer import SimpleTrainer\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from src.utils import dataset\n",
    "from src.optimizers.HypercubeTrainer import HypercubeTrainer\n",
    "from src.utils.evaluation import evaluate_accuracy\n",
    "from src.cert import Safebox"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-01T10:56:35.411337Z",
     "start_time": "2025-06-01T10:56:34.513951Z"
    }
   },
   "id": "c675c831c2e4942d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-01T10:56:37.379990Z",
     "start_time": "2025-06-01T10:56:37.320295Z"
    }
   },
   "id": "1a0613def2799a06",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "def get_model(seed=0, output_dim=10):\n",
    "    \"\"\"Returns a simple CNN model.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 8, kernel_size=5, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(8, 1, kernel_size=5, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(576, output_dim),\n",
    "    ).to(DEVICE)\n",
    "    return model\n",
    "def get_model_cifar10(seed=0, output_dim=10):\n",
    "    \"\"\"Returns a simple CNN model.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(3, 8, kernel_size=5, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(8, 3, kernel_size=5, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(2352, output_dim),\n",
    "    ).to(DEVICE)\n",
    "    return model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-01T10:56:38.150188Z",
     "start_time": "2025-06-01T10:56:38.129864Z"
    }
   },
   "id": "4e0a95cef96b5757",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "from src.utils.dataset import reduce_dataset\n",
    "\n",
    "train_dataset, val_dataset = dataset.get_fashion_mnist_dataset()\n",
    "train_dataset = reduce_dataset(train_dataset, num_samples=300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-01T10:56:42.925251Z",
     "start_time": "2025-06-01T10:56:40.383560Z"
    }
   },
   "id": "9046dfd0a62bb615",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:01<00:00, 22.4MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 684kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:00<00:00, 13.4MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 541kB/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [01:24<00:00, 35.60it/s, loss=0.115, val_acc=0.719] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Training completed with loss  0 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "simple_model = get_model()\n",
    "trainer = SimpleTrainer(simple_model, device=DEVICE)\n",
    "simple_model = trainer.train(train_dataset, val_dataset, loss_obj=0.000000000000001, max_iters=3000, batch_size=64, lr=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-31T23:03:58.015550Z",
     "start_time": "2025-05-31T23:02:33.139480Z"
    }
   },
   "id": "73033846897c5935",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Simple Training 0.7263000011444092\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Simple Training\", evaluate_accuracy(val_dataset, simple_model, num_samples=10000, device=DEVICE))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-31T22:04:52.160889Z",
     "start_time": "2025-05-31T22:04:49.850Z"
    }
   },
   "id": "511d020827ebfaec",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [03:05<00:00, 16.21it/s, loss=0.0414, min_val_acc=0.609]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Training completed with loss  0 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = get_model(output_dim=10)\n",
    "optimizer = HypercubeTrainer(model, device=DEVICE)\n",
    "optimizer.set_volume_constrain(1e-5*5) # start with a small volume at first \n",
    "optimizer.train(\n",
    "    train_dataset, val_dataset, loss_obj=0.000000000000001, max_iters=3000, batch_size=64, lr=1e-4\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-31T22:07:57.704479Z",
     "start_time": "2025-05-31T22:04:52.162412Z"
    }
   },
   "id": "3eb30db4134b45e0",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.7210000157356262\n"
     ]
    }
   ],
   "source": [
    "model = Safebox.bmodelToModel(optimizer.result())\n",
    "print(\"Accuracy \", evaluate_accuracy(val_dataset, model, num_samples=10000))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-31T22:08:00.470872Z",
     "start_time": "2025-05-31T22:07:57.706993Z"
    }
   },
   "id": "c6ee958cc44c873e",
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Lagrangian experiments",
   "id": "2a9f8a6e5c2d2bab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T11:35:18.982637Z",
     "start_time": "2025-06-01T11:35:14.598791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = get_model(output_dim=10).to('cpu')\n",
    "optimizer = LagrangianTrainer(model, device='cpu')\n",
    "optimizer.set_volume_constrain(1e-5*5) # start with a small volume at first\n",
    "optimizer.train(\n",
    "    train_dataset, val_dataset, loss_obj=0.000000000000001, max_iters=3000, batch_size=64, lr=1e-4\n",
    ")"
   ],
   "id": "b80923e351a1571",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/3000 [00:00<01:51, 26.94it/s, loss=nan, min_val_acc=0.188] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4332, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2188, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/3000 [00:00<01:53, 26.24it/s, loss=nan, min_val_acc=0.109] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/3000 [00:00<01:55, 25.82it/s, loss=nan, min_val_acc=0.0781]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/3000 [00:00<01:53, 26.15it/s, loss=nan, min_val_acc=0.172] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/3000 [00:01<01:53, 26.14it/s, loss=nan, min_val_acc=0.0938]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 33/3000 [00:01<01:54, 25.83it/s, loss=nan, min_val_acc=0.109] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 39/3000 [00:01<01:52, 26.36it/s, loss=nan, min_val_acc=0.0469]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 45/3000 [00:01<01:51, 26.60it/s, loss=nan, min_val_acc=0.109] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 51/3000 [00:02<01:49, 26.89it/s, loss=nan, min_val_acc=0.109] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 57/3000 [00:02<01:52, 26.19it/s, loss=nan, min_val_acc=0.0469]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 63/3000 [00:02<01:53, 25.81it/s, loss=nan, min_val_acc=0.0625]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 69/3000 [00:02<01:53, 25.77it/s, loss=nan, min_val_acc=0.109] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 75/3000 [00:02<01:53, 25.74it/s, loss=nan, min_val_acc=0.0625]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 81/3000 [00:03<01:52, 25.88it/s, loss=nan, min_val_acc=0.0938]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 87/3000 [00:03<01:52, 25.93it/s, loss=nan, min_val_acc=0.0781]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 93/3000 [00:03<01:51, 25.97it/s, loss=nan, min_val_acc=0.0781]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 99/3000 [00:03<01:54, 25.25it/s, loss=nan, min_val_acc=0.0938]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 105/3000 [00:04<01:53, 25.54it/s, loss=nan, min_val_acc=0.0781]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 110/3000 [00:04<01:51, 25.85it/s, loss=nan, min_val_acc=0.0781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "tensor(nan, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[37]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m optimizer = LagrangianTrainer(model, device=\u001B[33m'\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      3\u001B[39m optimizer.set_volume_constrain(\u001B[32m1e-5\u001B[39m*\u001B[32m5\u001B[39m) \u001B[38;5;66;03m# start with a small volume at first\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_obj\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.000000000000001\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iters\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1e-4\u001B[39;49m\n\u001B[32m      6\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<string>:16\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(self, train_dataset, val_dataset, loss_obj, max_iters, batch_size, lr, **kwargs)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/cours/MA2/Opti/project/src/optimizers/ConstrainedVolumeTrainer.py:39\u001B[39m, in \u001B[36mConstrainedVolumeTrainer.train\u001B[39m\u001B[34m(self, train_dataset, val_dataset, loss_obj, max_iters, batch_size, lr, **kwargs)\u001B[39m\n\u001B[32m     37\u001B[39m \u001B[38;5;28mself\u001B[39m._interval_model.train()\n\u001B[32m     38\u001B[39m \u001B[38;5;28mself\u001B[39m._current_val_dataset=val_dataset\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[43m    \u001B[49m\u001B[43mval_dataset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m    \u001B[49m\u001B[43mloss_obj\u001B[49m\u001B[43m=\u001B[49m\u001B[43mloss_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_iters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/cours/MA2/Opti/project/src/optimizers/Trainer.py:30\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, train_dataset, val_dataset, loss_obj, max_iters, batch_size, lr, **kwargs)\u001B[39m\n\u001B[32m     28\u001B[39m     X, y = \u001B[38;5;28mnext\u001B[39m(data_iter)\n\u001B[32m     29\u001B[39m X, y = X.to(\u001B[38;5;28mself\u001B[39m._device), y.to(\u001B[38;5;28mself\u001B[39m._device)\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m loss, info_dict = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     31\u001B[39m progress_bar.set_postfix({\n\u001B[32m     32\u001B[39m                              \u001B[33m\"\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mround\u001B[39m(loss, \u001B[32m4\u001B[39m),\n\u001B[32m     33\u001B[39m                          } | info_dict)\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m loss < loss_obj:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/cours/MA2/Opti/project/src/optimizers/ConstrainedVolumeTrainer.py:64\u001B[39m, in \u001B[36mConstrainedVolumeTrainer.step\u001B[39m\u001B[34m(self, X, y, lr, **kwargs)\u001B[39m\n\u001B[32m     62\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: torch.Tensor, y: torch.Tensor, lr: \u001B[38;5;28mfloat\u001B[39m = \u001B[32m1e-4\u001B[39m, **kwargs) -> (\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]):\n\u001B[32m     63\u001B[39m     \u001B[38;5;28mself\u001B[39m._interval_model.train()\n\u001B[32m---> \u001B[39m\u001B[32m64\u001B[39m     loss, infos = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_optimize_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     65\u001B[39m     min_acc = \u001B[38;5;28mround\u001B[39m(\u001B[38;5;28mself\u001B[39m._evaluate_min_val_acc(\u001B[38;5;28mself\u001B[39m._current_val_dataset, \u001B[32m64\u001B[39m), \u001B[32m4\u001B[39m)\n\u001B[32m     66\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m loss, {\u001B[33m\"\u001B[39m\u001B[33mmin_val_acc\u001B[39m\u001B[33m\"\u001B[39m: min_acc} | infos\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<string>:10\u001B[39m, in \u001B[36m_optimize_step\u001B[39m\u001B[34m(self, X, y, lr, **kwargs)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/libraries/miniconda3/envs/opti/lib/python3.13/site-packages/cooper/optim/constrained_optimizers/alternating_optimizer.py:232\u001B[39m, in \u001B[36mAlternatingDualPrimalOptimizer.roll\u001B[39m\u001B[34m(self, compute_cmp_state_kwargs)\u001B[39m\n\u001B[32m    229\u001B[39m \u001B[38;5;66;03m# Update primal variables based on the Lagrangian at the new dual point, and the\u001B[39;00m\n\u001B[32m    230\u001B[39m \u001B[38;5;66;03m# objective and constraint violations measured at the old primal point.\u001B[39;00m\n\u001B[32m    231\u001B[39m primal_lagrangian_store = cmp_state.compute_primal_lagrangian()\n\u001B[32m--> \u001B[39m\u001B[32m232\u001B[39m \u001B[43mprimal_lagrangian_store\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    233\u001B[39m \u001B[38;5;28mself\u001B[39m.primal_step()\n\u001B[32m    235\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m RollOut(cmp_state.loss, cmp_state, primal_lagrangian_store, dual_lagrangian_store)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/libraries/miniconda3/envs/opti/lib/python3.13/site-packages/cooper/cmp.py:40\u001B[39m, in \u001B[36mLagrangianStore.backward\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     36\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Triggers backward calls to compute the gradient of the Lagrangian with\u001B[39;00m\n\u001B[32m     37\u001B[39m \u001B[33;03mrespect to the primal variables.\u001B[39;00m\n\u001B[32m     38\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     39\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.lagrangian \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlagrangian\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/libraries/miniconda3/envs/opti/lib/python3.13/site-packages/torch/_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/libraries/miniconda3/envs/opti/lib/python3.13/site-packages/torch/autograd/__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/libraries/miniconda3/envs/opti/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": [
    "model = Safebox.bmodelToModel(optimizer.result())\n",
    "print(\"Accuracy \", evaluate_accuracy(val_dataset, model, num_samples=10000))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-01T11:19:20.252182Z",
     "start_time": "2025-06-01T11:19:18.788649Z"
    }
   },
   "id": "b9d6317752bffce3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.12359999865293503\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60ed13093b04b25a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
