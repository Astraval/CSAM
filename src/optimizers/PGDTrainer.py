import copy
import torch
from src.optimizers.Trainer import Trainer
from src.optimizers.sam import SAM
from src.utils.evaluation import evaluate_accuracy


class PGDTrainer(Trainer):
    """
    Trainer that implements adversarial training using Projected Gradient Descent attacks.
    It trains a standard model to be robust against adversarial examples.
    """
    
    def __init__(self, model: torch.nn.Sequential, quiet: bool = False, device: str = "cpu"):
        """Initializes the PGDTrainer.

        Args:
            model (torch.nn.Sequential): The neural network model to be trained adversarially.
            quiet (bool, optional): If True, suppresses training output. Defaults to False.
            device (str, optional): The device to use for training ('cpu' or 'cuda'). Defaults to "cpu".
        """
        super().__init__(quiet=quiet, device=device)
        self._val_dataset = None
        self._optimizer: torch.optim.Optimizer | None = None
        self._model = copy.deepcopy(model).to(device)
    
    
    def train(self,
              train_dataset: torch.utils.data.Dataset,
              val_dataset: torch.utils.data.Dataset,
              loss_obj: float, max_iters: int = 100,
              batch_size: int = 64, lr: float = 1e-4, epsilon: float = 0.3, alpha: float = 0.01, num_iters: int = 10,
              data_domain: tuple[float] = (0.0, 1.0), **kwargs) -> bool:
        """Trains the model using adversarial examples generated by the PGD attack.

        Args:
            train_dataset (torch.utils.data.Dataset): The dataset used for training
            val_dataset (torch.utils.data.Dataset): The dataset used for validation
            loss_obj (float): the target loss value to reach
            max_iters (int, optional): Maximum number of training iterations. Defaults to 100.
            batch_size (int, optional): Number of samples per training batch. Defaults to 64.
            lr (float, optional): Learning rate for the optimizer. Defaults to 1e-4.
            epsilon (float, optional): Maximum perturbation for the PGD attack. Defaults to 0.3.
            alpha (float, optional): Step size for the PGD attack. Defaults to 0.01.
            num_iters (int, optional): Number of PGD steps for generating adversarial examples. Defaults to 10.
            data_domain (tuple[float], optional): Minimum and maximum values for input data. Defaults to (0.0, 1.0).

        Returns:
            bool: True if training completes successfully, otherwise False.
        """
        
        self._optimizer = torch.optim.Adam(self._model.parameters(), lr=lr)
        self._val_dataset = val_dataset
        return super().train(
            train_dataset=train_dataset,
            val_dataset=val_dataset,
            loss_obj=loss_obj,
            batch_size=batch_size,
            lr=lr,
            max_iters=max_iters,
            epsilon=epsilon,
            alpha=alpha,
            num_iters=num_iters,
            data_domain=data_domain,
            **kwargs
        )

    def _pgd_attack(self, model: torch.nn, x: torch.Tensor, y: torch.Tensor, epsilon: float, alpha: float, num_iter,
                    clamp_min: float = 0.0, clamp_max: float = 1):
        """Generates adversarial examples using the Projected Gradient Descent (PGD) attack.

        Args:
            model (torch.nn): The model to attack
            x (torch.Tensor): the input batch
            y (torch.Tensor): The true labels for the batch.
            epsilon (float): Maximum allowed perturbation.
            alpha (float): Step size for each PGD iteration
            num_iter (_type_): Number of PGD steps
            clamp_min (float, optional): Minimum value for input data. Defaults to 0.0.
            clamp_max (float, optional): Maximum value for input data. Defaults to 1.

        Returns:
            torch.Tensor: The adversarially perturbed input batch.
        """
        x_adv = x.clone().detach().requires_grad_(True)
        for _ in range(num_iter):
            model.zero_grad()
            self._optimizer.zero_grad()  # just to be absolutely certain intermediate steps are not somehow saved
            output = model(x_adv)
            loss = torch.nn.CrossEntropyLoss()(output, y)
            loss.backward()
            with torch.no_grad():
                x_adv += alpha * x_adv.grad.sign()
                x_adv = torch.max(torch.min(x_adv, x + epsilon),  # constrain x in epsilon ball
                                  x - epsilon)
                x_adv = torch.clamp(x_adv, clamp_min, clamp_max)
            x_adv = x_adv.clone().detach().requires_grad_(True)
        return x_adv.clone().detach().requires_grad_(False)  # prevent torch from applying chain rule on x_adv

    def step(self, X: torch.Tensor, y: torch.Tensor,
             lr: float = 1e-4, epsilon: float = 0.3,
             alpha: float = 0.01, num_iters: int = 10,
             data_domain: tuple[float] = (0.0, 1.0), **kwargs) -> (float, dict[str, float]):
        """Performs one adversarial training step using PGD and updates the model parameters.

        Args:
            dict (_type_): _description_

        Returns:
            _type_: _description_
        """
        self._model.train()
        self._model.zero_grad()
        self._optimizer.zero_grad()
        x_adv = self._pgd_attack(self._model, X, y, epsilon, alpha, num_iters,
                                 clamp_min=data_domain[0], clamp_max=data_domain[1])
        self._model.train()
        self._model.zero_grad()
        self._optimizer.zero_grad()  # extra cautious to not accidentally propagate gradients
        y_pred = self._model(x_adv)
        loss = torch.nn.CrossEntropyLoss()(y_pred, y)
        loss.backward()
        self._optimizer.step()
        accuracy = self._evaluate_accuracy()
        return loss.item(), {"val_acc": round(accuracy, 4)}

    def result(self) -> torch.nn.Sequential:
        """
        Returns a copy of the trained model
        """
        return copy.deepcopy(self._model)

    def _evaluate_accuracy(self, num_samples: int = 64) -> float:
        """Evaluates the model's accuracy on the validation dataset.

        Args:
            num_samples (int, optional): Number of samples to use for evaluation. Defaults to 64.

        Returns:
            float: The computed accuracy on the validation set.
        """
        self._model.eval()
        with torch.inference_mode():
            return evaluate_accuracy(self._val_dataset, self._model, num_samples=num_samples, device=self._device)
